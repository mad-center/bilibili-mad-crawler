# 爬虫时间成本

## 单节点-单线程

> 爬取效率=1

- 设置 ps=50（bilibili API分页容量上限）。
- 此时 total_count=16569页。
- 记一页爬取时间为X秒。

计算总时间：

```
time_cost= (total_count * X)/3600= 16569X/3600= 4.6025 * X (小时)
```

X 的合理取值为1~5秒之间。

- 取值太低，爬虫过快，会被限流。
- 取值太高，那么爬虫等待时间就越长，完成所花费的总时间就越长。

假设取值2，那么就是9小时左右。

## 单节点-多线程

> 爬取效率=并行的线程数量=8

假设有8个线程并行请求，每一个请求对应一页。每一轮间隔等待2秒。那么1秒可以抓取数据条数= 8*50/2=200。 80W/200/3600= 1.1 小时左右。

## 还能更快一点吗？

考虑爬虫的性能扩展，可以从这两个方面入手：

- 水平扩展（多节点-多线程）：增加爬虫Node，也就是多个爬虫App。
- 垂直扩展（单节点-多线程 ↑）：增加单机器的硬件资源，主要是CPU的内核数，因为内核数间接决定并行请求的有效线程数。

### 水平扩展

> 爬取效率=单位Node并行的线程数量 * Node数量 = 8 * node_num

将爬虫程序看做Node，复制多个Node来运行。每个Node都是同构的，无状态的。状态的管理依旧放到**爬虫进度表**中。

这属于分布式爬虫，要特别注意一个问题：多个Node同时对爬虫进度表同一个文档的读写问题。

- 典型的python爬虫技术是 scrapy + redis。redis 的 setIfNotExist自带分布式锁。

- 如果不想再多使用一个数据库redis，只想继续使用mongodb，那就需要考虑mongodb爬虫进度表中的文档锁（行锁）。

不管技术如何选型，流程都是这样：

- 部署多个爬虫Node。每个Node每次随机选取固定数量（例如8个）的page_nums，然后瞬发并行请求。
- 特定page_num的请求正常返回后，插入video数据到db，同时以锁方式更新爬虫进度表中的对应page_num的document。
- 上面的锁方式，可以是乐观锁，也可以是悲观锁。总之，一定要保证数据正确性。
- 优化方面：【插入video数据到db + 更新爬虫进度表】这个步骤，涉及数据库的多个写操作，最好开启事务。

### 垂直扩展

> 爬取效率=并行的线程数量 * 1 Node = ? * 1

典型的金钱换时间，成本很高。购买更强的CPU，例如16，或者32个线程的CPU。

假设对于MAD分区，80w数据量，32个线程并行，2秒间隔等待，在bili server能瞬间返回响应的理想情况下，需要1.1/4=0.275小时，大约16.5分钟。