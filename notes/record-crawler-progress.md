# 记录爬虫进度，中断和恢复

当需要爬虫的数据量很大时，短时间完成所有爬虫是不可能的。而且，由于爬虫涉及网络请求，程序处理，
数据库读写多方面的操作，很容易发生异常导致爬虫进度中断。

那么，就产生了以下问题：
- 如何记录爬虫当前已完成的进度？
- 如何从中断的位置开始，恢复爬虫？

爬虫本身应该是state-less的，也就是无状态。任何需要持久化的数据都应该放入数据库层。
保存爬虫进度，本质上是**保存当前情境的上下文**。

在当前分页爬取这个案例中，具体来说就是：
```
保存已成功爬取的page_number
```
例如page_number是50，代表1-50页已经被正常爬取，程序应当从51页开始继续运行。
page_number初始值是0。

## 其他保存进度的思路
- 将爬虫进度上下文信息保存进本地文件。
- 如果爬取的是图片URL，且URL已知。可以将URL批量先保存进数据库。每次爬虫成功，就标记一下爬取成功。
  剩余爬虫只会从未标记成功的URL列表中取。
- 将爬虫进度上下文信息保存进redis。redis 双端队列。一个push，一个pop。爬虫程序属于消费者，只会pop。

## 实现细节
在mongodb test数据中新建一个collection，名称 mad_crawler_page。
字段如下：

|字段|类型|描述|
|---|---|---|
|_id|ObjectId|自带的ID标志|
|page|Int32|页码|
|last_update|datetime|UTC 日期时间|